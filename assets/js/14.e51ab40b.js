(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{350:function(s,t,a){s.exports=a.p+"assets/img/k-means1.6bca06c5.png"},382:function(s,t,a){"use strict";a.r(t);var n=a(42),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("h1",{attrs:{id:"k-means-聚类算法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#k-means-聚类算法"}},[s._v("#")]),s._v(" K-Means 聚类算法")]),s._v(" "),n("h2",{attrs:{id:"_1-k-means-简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-k-means-简介"}},[s._v("#")]),s._v(" 1. K-Means 简介")]),s._v(" "),n("ol",[n("li",[s._v("K-Means 原理: 对于给定的样本集，按照样本之间的距离大小，将样本集划分为K个簇。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大")]),s._v(" "),n("li",[s._v("传统 K-Means 流程\n"),n("ol",[n("li",[s._v("选择k值")]),s._v(" "),n("li",[s._v("随机选择k个初始化质心")]),s._v(" "),n("li",[s._v("计算样本到各个质心的距离, 按照距离最小划分类别")]),s._v(" "),n("li",[s._v("重新选择质心, 重复第3步骤")]),s._v(" "),n("li",[s._v("若质心向量不变则输出分区, 负责重新选择质心")])])]),s._v(" "),n("li",[s._v("K-Means++ 算法\n"),n("ol",[n("li",[s._v("质心优化: 第一个质心随机选择, 与当前质心距离较远的点被选择聚类中心的概率较大")])])]),s._v(" "),n("li",[s._v("K-Means 距离计算优化 elkan\n"),n("ol",[n("li",[s._v("目的是减少不必要的距离计算")]),s._v(" "),n("li",[s._v("原理:三角形两边之和大于等于第三边, 两边只差小于第三边\n"),n("ol",[n("li",[s._v("如果预先知道两个质心的距离D(j1, j2), 若点x到满足2D(x, j1) < D(x, j2), 则D(x, j1) < D(x, j2)")]),s._v(" "),n("li",[s._v("D(x, j1) ≥ max{0, D(x, j1)-D(j1, j2)}")])])]),s._v(" "),n("li",[s._v("样本稀疏的情况下不适用")])])]),s._v(" "),n("li",[s._v("大样本优化 Mini Batch K-Means\n"),n("ol",[n("li",[s._v("用样本中的一部分样本(batch size)来做传统的K-Means")]),s._v(" "),n("li",[s._v("精度会有所下降, 一般会多跑几次, 选择最优")])])])]),s._v(" "),n("h2",{attrs:{id:"_2-源码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-源码"}},[s._v("#")]),s._v(" 2. 源码")]),s._v(" "),n("ol",[n("li",[n("p",[s._v("基于sklearn的K-Means算法")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cluster "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" KMeans\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" make_blobs\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建数据集")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# x为样本特征, y为样本簇类别, 1000样本, 每个样本两个特征")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 共4个簇, 簇中心为[1, 1], [1, -1], [-1, 1], [-1, -1], 簇方差为分别[0.4, 0.4, 0.2, 0.2]")]),s._v("\nx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" make_blobs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_samples"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_features"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" centers"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n               cluster_std"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# plt.scatter(x[:, 0], x[:, 1], marker='o')")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# plt.show()")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# n_clusters: K值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# max_iter: 最大迭代次数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# n_init: 用不同初始化之心运行算法的次数, 默认10. K较大时可适当增大")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# init: 初始值选择方式, 随机选择'random', 优化过的'k-means++', 一般用默认的'k-means++'")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# algorithm: 'auto', 'full', 'elkan'三种选择, 一般用默认'auto'")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# random_state: 用于随机产生中心的随机序列")]),s._v("\ny_pred "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" KMeans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_clusters"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" random_state"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit_predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 下面三行与上面这句等价")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# km = KMeans(n_clusters=4, random_state=2)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# km.fit(x)")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# y_pred = km.predict(x)")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" c"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("y_pred"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br")])])]),s._v(" "),n("li",[n("p",[s._v("输出结果")]),s._v(" "),n("p",[n("img",{attrs:{src:a(350),alt:"k-means1"}})])])]),s._v(" "),n("h2",{attrs:{id:"_3-参考"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-参考"}},[s._v("#")]),s._v(" 3. 参考")]),s._v(" "),n("ul",[n("li",[n("a",{attrs:{href:"https://www.cnblogs.com/pinard/p/6164214.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("K-Means聚类算法原理"),n("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=e.exports}}]);